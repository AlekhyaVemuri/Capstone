# ğŸ§¬ Sequential Sentence Classification â€” PubMed 20k RCT
## AI Engineer Capstone Project

---

## ğŸ“ Project Structure

```
capstone_project/
â”œâ”€â”€ Sequential_Sentence_Classification.ipynb   â† Main notebook (42 cells, 11 sections)
â”œâ”€â”€ setup_venv.bat                             â† Windows setup (Command Prompt)
â”œâ”€â”€ setup_venv.ps1                             â† Windows setup (PowerShell)
â”œâ”€â”€ README.md                                  â† This file
â””â”€â”€ pubmed_data/
    â””â”€â”€ PubMed_20k_RCT/
        â”œâ”€â”€ train.txt   (~180k sentences, ~15k abstracts)
        â”œâ”€â”€ dev.txt     (~30k sentences)
        â””â”€â”€ test.txt    (~30k sentences)
```

---

## âš™ï¸ Environment Setup â€” Windows (Python venv)

### Option A: Command Prompt / Double-click
```bat
setup_venv.bat
```

### Option B: PowerShell
```powershell
powershell -ExecutionPolicy Bypass -File setup_venv.ps1
```

### Option C: Manual steps
```bat
:: 1. Create venv â€” inherits system site-packages automatically
python -m venv --system-site-packages venv

:: 2. Activate
venv\Scripts\activate.bat

:: 3. (Optional) Install deep learning packages â€” needed for Models 2-4
pip install tensorflow==2.18.0 tensorflow-hub
pip install transformers==4.35.0
pip install torch==2.2.0

:: 4. Register Jupyter kernel and launch
pip install jupyter ipykernel
python -m ipykernel install --user --name=capstone_venv --display-name "Python (capstone_venv)"
jupyter notebook Sequential_Sentence_Classification.ipynb
```

> **Note:** Models 0 & 1 run immediately with core packages.
> Models 2â€“4 require the optional DL installs above.

---

## âš ï¸ PowerShell Execution Policy

If PowerShell blocks the script, run this once as Administrator:
```powershell
Set-ExecutionPolicy RemoteSigned -Scope CurrentUser
```
Or pass the bypass flag per-run:
```powershell
powershell -ExecutionPolicy Bypass -File setup_venv.ps1
```

---

## ğŸ¤– Models

| # | Model | Architecture | Expected Accuracy |
|---|---|---|---|
| 0 | NaÃ¯ve Bayes + TF-IDF | Classical ML baseline | ~73% |
| 1 | Conv1D Token Embedding | Token embed â†’ Multi-scale Conv1D â†’ Dense | ~81% |
| 2 | USE Feature Extractor | Universal Sentence Encoder (512d) â†’ Dense | ~84% |
| 3 | Conv1D Char Embedding | Char embed â†’ 5-kernel Conv1D â†’ Dense | ~79% |
| 4 | BERT Fine-tuning | bert-base-uncased â†’ [CLS] â†’ Linear head | ~90% |

---

## ğŸ“Š Labels

`BACKGROUND` Â· `OBJECTIVE` Â· `METHODS` Â· `RESULTS` Â· `CONCLUSIONS`

---

*Capstone Project | AI Engineer Program*
